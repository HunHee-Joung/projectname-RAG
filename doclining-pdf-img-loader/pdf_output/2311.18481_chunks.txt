=== 청크 1 ===
텍스트: Lokesh Mishra 1 , Cesar Berrospi 1 , Kasper Dinkla 1 , Diego Antognini 1 , Francesco Fusco 1 , Benedikt Bothur 2 , Maksym Lysak 1 , Nikolaos Livathinos 1 , Ahmed Nassar 1 , Panagiotis Vagenas 1 , Lucas Morin 1,3 , Christoph Auer 1 , Michele Dolfi 1 , Peter Staar 1
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/2', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.657, t=671.495, r=557.344, b=631.573, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 264))], orig='Lokesh Mishra 1 , Cesar Berrospi 1 , Kasper Dinkla 1 , Diego Antognini 1 , Francesco Fusco 1 , Benedikt Bothur 2 , Maksym Lysak 1 , Nikolaos Livathinos 1 , Ahmed Nassar 1 , Panagiotis Vagenas 1 , Lucas Morin 1,3 , Christoph Auer 1 , Michele Dolfi 1 , Peter Staar 1', text='Lokesh Mishra 1 , Cesar Berrospi 1 , Kasper Dinkla 1 , Diego Antognini 1 , Francesco Fusco 1 , Benedikt Bothur 2 , Maksym Lysak 1 , Nikolaos Livathinos 1 , Ahmed Nassar 1 , Panagiotis Vagenas 1 , Lucas Morin 1,3 , Christoph Auer 1 , Michele Dolfi 1 , Peter Staar 1', formatting=None, hyperlink=None)] headings=['ESG Accountability Made Easy: DocQA at Your Service'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 2 ===
텍스트: 1 IBM Research, R¨ uschlikon, Switzerland
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/3', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=223.675, t=629.276, r=388.327, b=619.055, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 41))], orig='1 IBM Research, R¨ uschlikon, Switzerland', text='1 IBM Research, R¨ uschlikon, Switzerland', formatting=None, hyperlink=None)] headings=['ESG Accountability Made Easy: DocQA at Your Service'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 3 ===
텍스트: { mis, ceb, dkl, ffu, mly, nli, ahn, pva, lum, cau, dol, taa } @zurich.ibm.com
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/4', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=157.817, t=616.966, r=454.184, b=608.096, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 78))], orig='{ mis, ceb, dkl, ffu, mly, nli, ahn, pva, lum, cau, dol, taa } @zurich.ibm.com', text='{ mis, ceb, dkl, ffu, mly, nli, ahn, pva, lum, cau, dol, taa } @zurich.ibm.com', formatting=None, hyperlink=None)] headings=['ESG Accountability Made Easy: DocQA at Your Service'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 4 ===
텍스트: 2 IBM Technology, Z¨ urich, Switzerland
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/5', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=228.173, t=607.358, r=383.828, b=597.137, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 39))], orig='2 IBM Technology, Z¨ urich, Switzerland', text='2 IBM Technology, Z¨ urich, Switzerland', formatting=None, hyperlink=None)] headings=['ESG Accountability Made Easy: DocQA at Your Service'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 5 ===
텍스트: { Benedikt.Bothur, Diego.Antognini } @ibm.com
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/6', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=209.946, t=595.048, r=402.055, b=586.178, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 45))], orig='{ Benedikt.Bothur, Diego.Antognini } @ibm.com', text='{ Benedikt.Bothur, Diego.Antognini } @ibm.com', formatting=None, hyperlink=None)] headings=['ESG Accountability Made Easy: DocQA at Your Service'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 6 ===
텍스트: 3 ETH Z¨ urich, Z¨ urich, Switzerland
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/7', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=237.742, t=585.44, r=374.259, b=575.219, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 37))], orig='3 ETH Z¨ urich, Z¨ urich, Switzerland', text='3 ETH Z¨ urich, Z¨ urich, Switzerland', formatting=None, hyperlink=None)] headings=['ESG Accountability Made Easy: DocQA at Your Service'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 7 ===
텍스트: We present Deep Search DocQA. This application enables information extraction from documents via a questionanswering conversational assistant. The system integrates several technologies from different AI disciplines consisting of document conversion to machine-readable format (via computer vision), finding relevant data (via natural language processing), and formulating an eloquent response (via large language models). Users can explore over 10,000 Environmental, Social, and Governance (ESG) disclosure reports from over 2000 corporations. The Deep Search platform can be accessed at: https://ds4sd.github.io.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/9', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=63.963, t=549.565, r=282.537, b=442.241, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 614))], orig='We present Deep Search DocQA. This application enables information extraction from documents via a questionanswering conversational assistant. The system integrates several technologies from different AI disciplines consisting of document conversion to machine-readable format (via computer vision), finding relevant data (via natural language processing), and formulating an eloquent response (via large language models). Users can explore over 10,000 Environmental, Social, and Governance (ESG) disclosure reports from over 2000 corporations. The Deep Search platform can be accessed at: https://ds4sd.github.io.', text='We present Deep Search DocQA. This application enables information extraction from documents via a questionanswering conversational assistant. The system integrates several technologies from different AI disciplines consisting of document conversion to machine-readable format (via computer vision), finding relevant data (via natural language processing), and formulating an eloquent response (via large language models). Users can explore over 10,000 Environmental, Social, and Governance (ESG) disclosure reports from over 2000 corporations. The Deep Search platform can be accessed at: https://ds4sd.github.io.', formatting=None, hyperlink=None)] headings=['Abstract'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 8 ===
텍스트: The global impact of climate change has galvanized organizations to announce key information about their environmental footprint (carbon emissions, energy usage, waste emission and management, etc.). Integrating sustainability information into the company reporting cycle is one of the targets of the UN 2030 Agenda for Sustainable Development and institutions like Principles for Responsible Investing (a UN-supported network of investors) encourage investors to incorporate this information into their investment decisions . Companies are thus increasingly disclosing environmental, social, and governance (ESG) data in their ESG reports, typically as PDF files.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/11', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=408.673, r=292.505, b=279.573, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 664))], orig='The global impact of climate change has galvanized organizations to announce key information about their environmental footprint (carbon emissions, energy usage, waste emission and management, etc.). Integrating sustainability information into the company reporting cycle is one of the targets of the UN 2030 Agenda for Sustainable Development and institutions like Principles for Responsible Investing (a UN-supported network of investors) encourage investors to incorporate this information into their investment decisions . Companies are thus increasingly disclosing environmental, social, and governance (ESG) data in their ESG reports, typically as PDF files.', text='The global impact of climate change has galvanized organizations to announce key information about their environmental footprint (carbon emissions, energy usage, waste emission and management, etc.). Integrating sustainability information into the company reporting cycle is one of the targets of the UN 2030 Agenda for Sustainable Development and institutions like Principles for Responsible Investing (a UN-supported network of investors) encourage investors to incorporate this information into their investment decisions . Companies are thus increasingly disclosing environmental, social, and governance (ESG) data in their ESG reports, typically as PDF files.', formatting=None, hyperlink=None)] headings=['Introduction'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 9 ===
텍스트: Unlike financial data, regulators such as the U.S. SEC do not require public companies to file ESG data with specific forms. There have been massive efforts from several organizations to standardize these reports. However, major challenges continue to persist, including complex regulations, rapidly evolving reporting frameworks, verifying ESG compliance, among others. These matters become more complicated when we realize that most of the ESG reporting is done in non machine-readable formats. Unlocking this vast amount of data in an easily consumable manner would greatly help researchers, policy-makers, lawyers, and corporations by extracting information and gaining insights.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/12', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=277.1569999999999, r=292.505, b=148.05700000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 683))], orig='Unlike financial data, regulators such as the U.S. SEC do not require public companies to file ESG data with specific forms. There have been massive efforts from several organizations to standardize these reports. However, major challenges continue to persist, including complex regulations, rapidly evolving reporting frameworks, verifying ESG compliance, among others. These matters become more complicated when we realize that most of the ESG reporting is done in non machine-readable formats. Unlocking this vast amount of data in an easily consumable manner would greatly help researchers, policy-makers, lawyers, and corporations by extracting information and gaining insights.', text='Unlike financial data, regulators such as the U.S. SEC do not require public companies to file ESG data with specific forms. There have been massive efforts from several organizations to standardize these reports. However, major challenges continue to persist, including complex regulations, rapidly evolving reporting frameworks, verifying ESG compliance, among others. These matters become more complicated when we realize that most of the ESG reporting is done in non machine-readable formats. Unlocking this vast amount of data in an easily consumable manner would greatly help researchers, policy-makers, lawyers, and corporations by extracting information and gaining insights.', formatting=None, hyperlink=None)] headings=['Introduction'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 10 ===
텍스트: To this end, we have developed Deep Search DocQA. The application offers users to perform document question answering (QA), i.e., users can extract information from any
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/13', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=145.64099999999996, r=292.505, b=115.17100000000005, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 168))], orig='To this end, we have developed Deep Search DocQA. The application offers users to perform document question answering (QA), i.e., users can extract information from any', text='To this end, we have developed Deep Search DocQA. The application offers users to perform document question answering (QA), i.e., users can extract information from any', formatting=None, hyperlink=None)] headings=['Introduction'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 11 ===
텍스트: Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/14', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=105.79999999999995, r=292.497, b=88.13999999999999, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 113))], orig='Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.', text='Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.', formatting=None, hyperlink=None)] headings=['Introduction'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 12 ===
텍스트: IBM 2022, Question = How many hours were spent on employee learning in 2021?. IBM 2022, Answer = 22.5 million hours. IBM 2022, Question = What was the rate of fatalities in 2021?. IBM 2022, Answer = The rate of fatalities in 2021 was 0.0016.. IBM 2022, Question = How many full audits were con- ducted in 2022 in India?. IBM 2022, Answer = 2. Starbucks 2022, Question = What is the percentage of women in the Board of Directors?. Starbucks 2022, Answer = 25%. Starbucks 2022, Question = What was the total energy con- sumption in 2021?. Starbucks 2022, Answer = According to the table, the total energy consumption in 2021 was 2,491,543 MWh.. Starbucks 2022, Question = How much packaging material was made from renewable mate- rials?. Starbucks 2022, Answer = According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TableItem(self_ref='#/tables/0', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TABLE: 'table'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=318.4306335449219, t=571.149658203125, r=559.6929931640625, b=375.6731872558594, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[], references=[], footnotes=[], image=None, data=TableData(table_cells=[TableCell(bbox=BoundingBox(l=325.478, t=226.84799999999996, r=346.392, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=0, end_col_offset_idx=1, text='Report', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=226.84799999999996, r=389.682, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=1, end_col_offset_idx=2, text='Question', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=226.84799999999996, r=491.296, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=2, end_col_offset_idx=3, text='Answer', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=242.08500000000004, r=338.652, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=242.08500000000004, r=376.327, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=1, end_col_offset_idx=2, text='How many hours were spent on employee learning in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=242.08500000000004, r=480.647, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=2, end_col_offset_idx=3, text='22.5 million hours', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=267.01199999999994, r=338.652, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=267.01199999999994, r=378.049, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=1, end_col_offset_idx=2, text='What was the rate of fatalities in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=267.01199999999994, r=479.287, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=2, end_col_offset_idx=3, text='The rate of fatalities in 2021 was 0.0016.', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=291.939, r=338.652, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=291.939, r=376.327, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=1, end_col_offset_idx=2, text='How many full audits were con- ducted in 2022 in India?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=291.939, r=471.93, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=2, end_col_offset_idx=3, text='2', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=316.867, r=352.843, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=316.867, r=378.049, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=1, end_col_offset_idx=2, text='What is the percentage of women in the Board of Directors?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=316.867, r=481.226, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=2, end_col_offset_idx=3, text='25%', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=341.794, r=352.843, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=341.794, r=378.049, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=1, end_col_offset_idx=2, text='What was the total energy con- sumption in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=341.794, r=497.879, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=2, end_col_offset_idx=3, text='According to the table, the total energy consumption in 2021 was 2,491,543 MWh.', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=325.478, t=376.684, r=352.843, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=376.684, r=376.327, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=1, end_col_offset_idx=2, text='How much packaging material was made from renewable mate- rials?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=376.684, r=497.879, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=2, end_col_offset_idx=3, text='According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22.', column_header=False, row_header=False, row_section=False)], num_rows=7, num_cols=3, grid=[[TableCell(bbox=BoundingBox(l=325.478, t=226.84799999999996, r=346.392, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=0, end_col_offset_idx=1, text='Report', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=226.84799999999996, r=389.682, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=1, end_col_offset_idx=2, text='Question', column_header=True, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=226.84799999999996, r=491.296, b=233.11800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=2, end_col_offset_idx=3, text='Answer', column_header=True, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=242.08500000000004, r=338.652, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=242.08500000000004, r=376.327, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=1, end_col_offset_idx=2, text='How many hours were spent on employee learning in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=242.08500000000004, r=480.647, b=248.07100000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=2, end_col_offset_idx=3, text='22.5 million hours', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=267.01199999999994, r=338.652, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=267.01199999999994, r=378.049, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=1, end_col_offset_idx=2, text='What was the rate of fatalities in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=267.01199999999994, r=479.287, b=272.99800000000005, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=2, end_col_offset_idx=3, text='The rate of fatalities in 2021 was 0.0016.', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=291.939, r=338.652, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=0, end_col_offset_idx=1, text='IBM 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=291.939, r=376.327, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=1, end_col_offset_idx=2, text='How many full audits were con- ducted in 2022 in India?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=291.939, r=471.93, b=297.925, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=2, end_col_offset_idx=3, text='2', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=316.867, r=352.843, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=316.867, r=378.049, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=1, end_col_offset_idx=2, text='What is the percentage of women in the Board of Directors?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=316.867, r=481.226, b=322.853, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=2, end_col_offset_idx=3, text='25%', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=341.794, r=352.843, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=341.794, r=378.049, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=1, end_col_offset_idx=2, text='What was the total energy con- sumption in 2021?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=341.794, r=497.879, b=347.78, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=5, end_row_offset_idx=6, start_col_offset_idx=2, end_col_offset_idx=3, text='According to the table, the total energy consumption in 2021 was 2,491,543 MWh.', column_header=False, row_header=False, row_section=False)], [TableCell(bbox=BoundingBox(l=325.478, t=376.684, r=352.843, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=0, end_col_offset_idx=1, text='Starbucks 2022', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=362.944, t=376.684, r=376.327, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=1, end_col_offset_idx=2, text='How much packaging material was made from renewable mate- rials?', column_header=False, row_header=False, row_section=False), TableCell(bbox=BoundingBox(l=468.443, t=376.684, r=497.879, b=382.67, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=6, end_row_offset_idx=7, start_col_offset_idx=2, end_col_offset_idx=3, text='According to the given data, 31% of packaging materials were made from recycled or renewable materials in FY22.', column_header=False, row_header=False, row_section=False)]]), annotations=[])] headings=['Introduction'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 13 ===
텍스트: Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/15', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=364.239, r=558.005, b=344.728, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 107))], orig='Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.', text='Table 1: Example question answers from the ESG reports of IBM and Starbucks using Deep Search DocQA system.', formatting=None, hyperlink=None)] headings=['Introduction'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 14 ===
텍스트: ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the response.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/16', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=320.006, r=558.005, b=278.577, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 211))], orig='ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the response.', text='ESG report in our library via our QA conversational assistant. Our assistant generates answers and also presents the information (paragraph or table), in the ESG report, from which it has generated the response.', formatting=None, hyperlink=None)] headings=['Introduction'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 15 ===
텍스트: The DocQA integrates multiple AI technologies, namely:
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/18', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=249.96000000000004, r=548.182, b=241.40800000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 54))], orig='The DocQA integrates multiple AI technologies, namely:', text='The DocQA integrates multiple AI technologies, namely:', formatting=None, hyperlink=None)] headings=['Related Work'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 16 ===
텍스트: Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al. 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based . Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/19', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=239.34000000000003, r=558.005, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 792))], orig='Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al. 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based . Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-', text='Document Conversion: Converting unstructured documents, such as PDF files, into a machine-readable format is a challenging task in AI. Early strategies for document conversion were based on geometric layout analysis (Cattoni et al. 2000; Breuel 2002). Thanks to the availability of large annotated datasets (PubLayNet (Zhong et al. 2019), DocBank (Li et al. 2020), DocLayNet (Pfitzmann et al. 2022; Auer et al. 2023), deep learning-based methods are routinely used. Modern approaches for recovering the structure of a document can be broadly divided into two categories: image-based or PDF representation-based . Imagebased methods usually employ Transformer or CNN architectures on the images of pages (Zhang et al. 2023; Li et al. 2022; Huang et al. 2022). On the other hand, deep learning-', formatting=None, hyperlink=None)] headings=['Related Work'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 17 ===
텍스트: Figure 1: System architecture: Simplified sketch of document question-answering pipeline.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/20', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=124.802, t=610.166, r=487.202, b=601.614, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 89))], orig='Figure 1: System architecture: Simplified sketch of document question-answering pipeline.', text='Figure 1: System architecture: Simplified sketch of document question-answering pipeline.', formatting=None, hyperlink=None)] headings=['Related Work'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 18 ===
텍스트: based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/44', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=576.99, r=292.505, b=546.52, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 179))], orig='based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).', text='based language processing methods are applied on the native PDF content (generated by a single PDF printing command) (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018).', formatting=None, hyperlink=None)] headings=['Related Work'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 19 ===
텍스트: Application of NLP to ESG: ESG reports contain large amount of useful data in textual and tabular format. There have been some attempts to use NLP on this data. Luccioni, Baylor, and Duchene (2020) developed ClimateQA, a model trained to classify whether a sentence from an ESG report answers regulatory questions. In addition, there are several works which aim to mine information from ESG reports for financial predictions (Guo et al. 2020; Goel et al. 2020). Nevertheless, to the best of our knowledge, no QA system which can extract data directly from an ESG report PDF has been reported in the literature.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/45', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=543.93, r=292.505, b=425.401, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 610))], orig='Application of NLP to ESG: ESG reports contain large amount of useful data in textual and tabular format. There have been some attempts to use NLP on this data. Luccioni, Baylor, and Duchene (2020) developed ClimateQA, a model trained to classify whether a sentence from an ESG report answers regulatory questions. In addition, there are several works which aim to mine information from ESG reports for financial predictions (Guo et al. 2020; Goel et al. 2020). Nevertheless, to the best of our knowledge, no QA system which can extract data directly from an ESG report PDF has been reported in the literature.', text='Application of NLP to ESG: ESG reports contain large amount of useful data in textual and tabular format. There have been some attempts to use NLP on this data. Luccioni, Baylor, and Duchene (2020) developed ClimateQA, a model trained to classify whether a sentence from an ESG report answers regulatory questions. In addition, there are several works which aim to mine information from ESG reports for financial predictions (Guo et al. 2020; Goel et al. 2020). Nevertheless, to the best of our knowledge, no QA system which can extract data directly from an ESG report PDF has been reported in the literature.', formatting=None, hyperlink=None)] headings=['Related Work'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 20 ===
텍스트: OCR, 2) analyze layout and segment it (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018) and 3) extract table structures (Lysak et al. 2023; Nassar et al. 2022). Finally, the data from multiple pages is assembled together, preserving the reading order, in a machine-readable format.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/46', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=576.99, r=558.005, b=524.603, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 293))], orig='OCR, 2) analyze layout and segment it (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018) and 3) extract table structures (Lysak et al. 2023; Nassar et al. 2022). Finally, the data from multiple pages is assembled together, preserving the reading order, in a machine-readable format.', text='OCR, 2) analyze layout and segment it (Auer et al. 2022; Livathinos et al. 2021; Staar et al. 2018) and 3) extract table structures (Lysak et al. 2023; Nassar et al. 2022). Finally, the data from multiple pages is assembled together, preserving the reading order, in a machine-readable format.', formatting=None, hyperlink=None)] headings=['Related Work'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 21 ===
텍스트: LLM & RAG: Due to the increasing scale of training data and model size, large language models (LLMs) demonstrate surprising emergent properties (Wei et al. 2022). For example, the behaviour of the GPT-3 model, with 175 billion parameters, could be modified with in-context learning (Brown et al. 2020; Bommasani et al. 2022; Raffel et al. 2020). Such LLMs are adaptable to a variety of downstream tasks via prompting and can be fine-tuned to better perform in a specific ESG domain (Webersinke et al. 2022). The Retrieval Augmented Generation (RAG) approach aims at improving the performance of these models on knowledge intensive tasks (Lewis et al. 2020). In this approach, the capabilities of natural language generation are combined with a knowledge index, from which relevant documents are retrieved.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/47', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=422.81, r=292.505, b=260.446, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 805))], orig='LLM & RAG: Due to the increasing scale of training data and model size, large language models (LLMs) demonstrate surprising emergent properties (Wei et al. 2022). For example, the behaviour of the GPT-3 model, with 175 billion parameters, could be modified with in-context learning (Brown et al. 2020; Bommasani et al. 2022; Raffel et al. 2020). Such LLMs are adaptable to a variety of downstream tasks via prompting and can be fine-tuned to better perform in a specific ESG domain (Webersinke et al. 2022). The Retrieval Augmented Generation (RAG) approach aims at improving the performance of these models on knowledge intensive tasks (Lewis et al. 2020). In this approach, the capabilities of natural language generation are combined with a knowledge index, from which relevant documents are retrieved.', text='LLM & RAG: Due to the increasing scale of training data and model size, large language models (LLMs) demonstrate surprising emergent properties (Wei et al. 2022). For example, the behaviour of the GPT-3 model, with 175 billion parameters, could be modified with in-context learning (Brown et al. 2020; Bommasani et al. 2022; Raffel et al. 2020). Such LLMs are adaptable to a variety of downstream tasks via prompting and can be fine-tuned to better perform in a specific ESG domain (Webersinke et al. 2022). The Retrieval Augmented Generation (RAG) approach aims at improving the performance of these models on knowledge intensive tasks (Lewis et al. 2020). In this approach, the capabilities of natural language generation are combined with a knowledge index, from which relevant documents are retrieved.', formatting=None, hyperlink=None)] headings=['Related Work'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 22 ===
텍스트: In this section, we describe the AI technologies which are integrated into our document question-answering application. The architecture is described in Fig. 1. The pipeline works end-to-end from PDF documents to question-answering using LLMs. It consists of three components described below.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/49', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=228.56399999999996, r=292.505, b=176.17700000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 292))], orig='In this section, we describe the AI technologies which are integrated into our document question-answering application. The architecture is described in Fig. 1. The pipeline works end-to-end from PDF documents to question-answering using LLMs. It consists of three components described below.', text='In this section, we describe the AI technologies which are integrated into our document question-answering application. The architecture is described in Fig. 1. The pipeline works end-to-end from PDF documents to question-answering using LLMs. It consists of three components described below.', formatting=None, hyperlink=None)] headings=['System Architecture'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 23 ===
텍스트: Document Conversion: The document conversion system is designed in an asynchronous task-based queueworker architecture. The user-facing API accepts documents in PDF format (both programmatically created and scanned). The client receives a task identifier, while an orchestrator enqueues several ML tasks to ephemeral workers. After splitting the document into pages, we: 1) depending on the nature of the PDF, we employ either PDF parsing or
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/50', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=173.586, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 441))], orig='Document Conversion: The document conversion system is designed in an asynchronous task-based queueworker architecture. The user-facing API accepts documents in PDF format (both programmatically created and scanned). The client receives a task identifier, while an orchestrator enqueues several ML tasks to ephemeral workers. After splitting the document into pages, we: 1) depending on the nature of the PDF, we employ either PDF parsing or', text='Document Conversion: The document conversion system is designed in an asynchronous task-based queueworker architecture. The user-facing API accepts documents in PDF format (both programmatically created and scanned). The client receives a task identifier, while an orchestrator enqueues several ML tasks to ephemeral workers. After splitting the document into pages, we: 1) depending on the nature of the PDF, we employ either PDF parsing or', formatting=None, hyperlink=None)] headings=['System Architecture'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 24 ===
텍스트: Information Retrieval: Using an encoder model, vector embeddings for the data in a document are computed and stored in a vector database. For text this is relatively straightforward, for tables the triplet of (cell content, column header, row header) is expressed as a sentence which gets encoded. The sentence expression is: string(column header) + string(row header) = string(cell content) 1 . We perform a k-nearest neighbour search to identify the top-k relevant passages for a user query. For sentence encoding, we use several encoding models from the Sentence Transformer library (Reimers and Gurevych 2019).
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/51', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=519.231, r=558.005, b=389.743, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 614))], orig='Information Retrieval: Using an encoder model, vector embeddings for the data in a document are computed and stored in a vector database. For text this is relatively straightforward, for tables the triplet of (cell content, column header, row header) is expressed as a sentence which gets encoded. The sentence expression is: string(column header) + string(row header) = string(cell content) 1 . We perform a k-nearest neighbour search to identify the top-k relevant passages for a user query. For sentence encoding, we use several encoding models from the Sentence Transformer library (Reimers and Gurevych 2019).', text='Information Retrieval: Using an encoder model, vector embeddings for the data in a document are computed and stored in a vector database. For text this is relatively straightforward, for tables the triplet of (cell content, column header, row header) is expressed as a sentence which gets encoded. The sentence expression is: string(column header) + string(row header) = string(cell content) 1 . We perform a k-nearest neighbour search to identify the top-k relevant passages for a user query. For sentence encoding, we use several encoding models from the Sentence Transformer library (Reimers and Gurevych 2019).', formatting=None, hyperlink=None)] headings=['System Architecture'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 25 ===
텍스트: Response Generation: We employ a suite of LLMs like LLAMA 2 (Touvron et al. 2023), Flan-UL2 (Tay et al. 2023), or T5 (Raffel et al. 2020) for generating a response to the user query. The user query and relevant context (identified by the previous model) are packaged together in a prompt for the LLM. The response of the model is checked against hate speech, abuse, and profanity. Finally the response is grounded in the context and inspected for hallucinations. If all tests are passed, the response is presented to the user via a virtual assistant. Table 1 shows some examples of questions and the generated answers by the system.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/52', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=384.371, r=558.005, b=265.842, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 632))], orig='Response Generation: We employ a suite of LLMs like LLAMA 2 (Touvron et al. 2023), Flan-UL2 (Tay et al. 2023), or T5 (Raffel et al. 2020) for generating a response to the user query. The user query and relevant context (identified by the previous model) are packaged together in a prompt for the LLM. The response of the model is checked against hate speech, abuse, and profanity. Finally the response is grounded in the context and inspected for hallucinations. If all tests are passed, the response is presented to the user via a virtual assistant. Table 1 shows some examples of questions and the generated answers by the system.', text='Response Generation: We employ a suite of LLMs like LLAMA 2 (Touvron et al. 2023), Flan-UL2 (Tay et al. 2023), or T5 (Raffel et al. 2020) for generating a response to the user query. The user query and relevant context (identified by the previous model) are packaged together in a prompt for the LLM. The response of the model is checked against hate speech, abuse, and profanity. Finally the response is grounded in the context and inspected for hallucinations. If all tests are passed, the response is presented to the user via a virtual assistant. Table 1 shows some examples of questions and the generated answers by the system.', formatting=None, hyperlink=None)] headings=['System Architecture'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 26 ===
텍스트: In this paper, we presented our DocQA application targeting ESG reports. The DocQA system can be useful for anyone, from policy-makers to students, trying to find information from a large document. Our future work is focused on enabling querying on multiple documents at once to extract aggregated insights for questions like 'How have the Scope 1 emissions evolved over the last decade?'. In addition, we will expand this service to other types of documents like scientific papers, financial reports, and patents.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/54', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=216.577, r=558.005, b=120.35400000000004, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 514))], orig="In this paper, we presented our DocQA application targeting ESG reports. The DocQA system can be useful for anyone, from policy-makers to students, trying to find information from a large document. Our future work is focused on enabling querying on multiple documents at once to extract aggregated insights for questions like 'How have the Scope 1 emissions evolved over the last decade?'. In addition, we will expand this service to other types of documents like scientific papers, financial reports, and patents.", text="In this paper, we presented our DocQA application targeting ESG reports. The DocQA system can be useful for anyone, from policy-makers to students, trying to find information from a large document. Our future work is focused on enabling querying on multiple documents at once to extract aggregated insights for questions like 'How have the Scope 1 emissions evolved over the last decade?'. In addition, we will expand this service to other types of documents like scientific papers, financial reports, and patents.", formatting=None, hyperlink=None)] headings=['Conclusions'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 27 ===
텍스트: 1 Here, string() returns the string representation of an object.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/55', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.FOOTNOTE: 'footnote'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=332.153, t=97.70000000000005, r=546.799, b=88.13999999999999, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 64))], orig='1 Here, string() returns the string representation of an object.', text='1 Here, string() returns the string representation of an object.', formatting=None, hyperlink=None)] headings=['Conclusions'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 28 ===
텍스트: Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. J. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) . IEEE.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/57', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=721.363, r=292.505, b=668.976, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 243))], orig='Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. J. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) . IEEE.', text='Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. J. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) . IEEE.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 29 ===
텍스트: Auer, C.; et al. 2023. ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. In Lecture Notes in Computer Science , 471-482. Springer Nature Switzerland.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/58', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=664.866, r=292.505, b=623.437, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 176))], orig='Auer, C.; et al. 2023. ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. In Lecture Notes in Computer Science , 471-482. Springer Nature Switzerland.', text='Auer, C.; et al. 2023. ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. In Lecture Notes in Computer Science , 471-482. Springer Nature Switzerland.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 30 ===
텍스트: Bommasani, R.; et al. 2022. On the Opportunities and Risks of Foundation Models. arXiv:2108.07258.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/59', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=619.327, r=292.505, b=599.817, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 98))], orig='Bommasani, R.; et al. 2022. On the Opportunities and Risks of Foundation Models. arXiv:2108.07258.', text='Bommasani, R.; et al. 2022. On the Opportunities and Risks of Foundation Models. arXiv:2108.07258.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 31 ===
텍스트: Breuel, T. M. 2002. Two Geometric Algorithms for Layout Analysis. In Lopresti, D.; Hu, J.; and Kashi, R., eds., Document Analysis Systems V , 188-199. Berlin, Heidelberg: Springer Berlin Heidelberg. ISBN 978-3-540-45869-2.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/60', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=595.707, r=292.505, b=554.278, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 222))], orig='Breuel, T. M. 2002. Two Geometric Algorithms for Layout Analysis. In Lopresti, D.; Hu, J.; and Kashi, R., eds., Document Analysis Systems V , 188-199. Berlin, Heidelberg: Springer Berlin Heidelberg. ISBN 978-3-540-45869-2.', text='Breuel, T. M. 2002. Two Geometric Algorithms for Layout Analysis. In Lopresti, D.; Hu, J.; and Kashi, R., eds., Document Analysis Systems V , 188-199. Berlin, Heidelberg: Springer Berlin Heidelberg. ISBN 978-3-540-45869-2.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 32 ===
텍스트: Brown, T. B.; et al. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/61', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=550.168, r=292.505, b=530.657, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 83))], orig='Brown, T. B.; et al. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165.', text='Brown, T. B.; et al. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 33 ===
텍스트: Cattoni, R.; Coianiz, T.; Messelodi, S.; and Modena, C. 2000. Geometric Layout Analysis Techniques for Document Image Understanding: a Review. Technical Report TR970309, ITC-irst, Via Sommarive 18, I-38050 Povo, Trento, Italy. Goel, T.; Jain, P.; Verma, I.; Dey, L.; and Paliwal, S. 2020. Mining company sustainability reports to aid financial decision-making. In The AAAI-20 Workshop on Knowledge Discovery from Unstructured Data in Financial Services .
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/62', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=526.548, r=292.505, b=439.58, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 454))], orig='Cattoni, R.; Coianiz, T.; Messelodi, S.; and Modena, C. 2000. Geometric Layout Analysis Techniques for Document Image Understanding: a Review. Technical Report TR970309, ITC-irst, Via Sommarive 18, I-38050 Povo, Trento, Italy. Goel, T.; Jain, P.; Verma, I.; Dey, L.; and Paliwal, S. 2020. Mining company sustainability reports to aid financial decision-making. In The AAAI-20 Workshop on Knowledge Discovery from Unstructured Data in Financial Services .', text='Cattoni, R.; Coianiz, T.; Messelodi, S.; and Modena, C. 2000. Geometric Layout Analysis Techniques for Document Image Understanding: a Review. Technical Report TR970309, ITC-irst, Via Sommarive 18, I-38050 Povo, Trento, Italy. Goel, T.; Jain, P.; Verma, I.; Dey, L.; and Paliwal, S. 2020. Mining company sustainability reports to aid financial decision-making. In The AAAI-20 Workshop on Knowledge Discovery from Unstructured Data in Financial Services .', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 34 ===
텍스트: Guo, T.; et al. 2020. ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility Prediction. arXiv:2005.02527.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/63', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=435.471, r=292.505, b=405.001, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 121))], orig='Guo, T.; et al. 2020. ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility Prediction. arXiv:2005.02527.', text='Guo, T.; et al. 2020. ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility Prediction. arXiv:2005.02527.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 35 ===
텍스트: Huang, Y.; et al. 2022. LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking. Proceedings of the 30th ACM International Conference on Multimedia .
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/64', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=400.891, r=292.505, b=370.421, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 170))], orig='Huang, Y.; et al. 2022. LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking. Proceedings of the 30th ACM International Conference on Multimedia .', text='Huang, Y.; et al. 2022. LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking. Proceedings of the 30th ACM International Conference on Multimedia .', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 36 ===
텍스트: Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; Goyal, N.; K¨ uttler, H.; Lewis, M.; Yih, W.-t.; Rockt¨ aschel, T.; Riedel, S.; and Kiela, D. 2020. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In Advances in Neural Information Processing Systems , volume 33, 9459-9474. Curran Associates, Inc.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/65', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=366.311, r=292.505, b=302.965, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 328))], orig='Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; Goyal, N.; K¨ uttler, H.; Lewis, M.; Yih, W.-t.; Rockt¨ aschel, T.; Riedel, S.; and Kiela, D. 2020. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In Advances in Neural Information Processing Systems , volume 33, 9459-9474. Curran Associates, Inc.', text='Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; Goyal, N.; K¨ uttler, H.; Lewis, M.; Yih, W.-t.; Rockt¨ aschel, T.; Riedel, S.; and Kiela, D. 2020. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In Advances in Neural Information Processing Systems , volume 33, 9459-9474. Curran Associates, Inc.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 37 ===
텍스트: Li, J.; et al. 2022. DiT: Self-supervised Pre-training for Document Image Transformer. Proceedings of the 30th ACM International Conference on Multimedia .
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/66', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=298.855, r=292.505, b=268.385, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 155))], orig='Li, J.; et al. 2022. DiT: Self-supervised Pre-training for Document Image Transformer. Proceedings of the 30th ACM International Conference on Multimedia .', text='Li, J.; et al. 2022. DiT: Self-supervised Pre-training for Document Image Transformer. Proceedings of the 30th ACM International Conference on Multimedia .', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 38 ===
텍스트: Li, M.; Xu, Y.; Cui, L.; Huang, S.; Wei, F.; Li, Z.; and Zhou, M. 2020. DocBank: A Benchmark Dataset for Document Layout Analysis. In Scott, D.; Bel, N.; and Zong, C., eds., Proceedings of the 28th International Conference on Computational Linguistics , 949-960. Barcelona, Spain (Online): International Committee on Computational Linguistics.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/67', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=264.275, r=292.505, b=200.92899999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 343))], orig='Li, M.; Xu, Y.; Cui, L.; Huang, S.; Wei, F.; Li, Z.; and Zhou, M. 2020. DocBank: A Benchmark Dataset for Document Layout Analysis. In Scott, D.; Bel, N.; and Zong, C., eds., Proceedings of the 28th International Conference on Computational Linguistics , 949-960. Barcelona, Spain (Online): International Committee on Computational Linguistics.', text='Li, M.; Xu, Y.; Cui, L.; Huang, S.; Wei, F.; Li, Z.; and Zhou, M. 2020. DocBank: A Benchmark Dataset for Document Layout Analysis. In Scott, D.; Bel, N.; and Zong, C., eds., Proceedings of the 28th International Conference on Computational Linguistics , 949-960. Barcelona, Spain (Online): International Committee on Computational Linguistics.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 39 ===
텍스트: Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Number: 17.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/68', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=196.81899999999996, r=292.505, b=133.47299999999996, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 297))], orig='Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Number: 17.', text='Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Number: 17.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 40 ===
텍스트: Luccioni, S.; Baylor, E.; and Duchene, N. 2020. Analyzing Sustainability Reports Using Natural Language Processing. In NeurIPS 2020 Workshop on Tackling Climate Change with Machine Learning .
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/69', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=129.36300000000006, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 191))], orig='Luccioni, S.; Baylor, E.; and Duchene, N. 2020. Analyzing Sustainability Reports Using Natural Language Processing. In NeurIPS 2020 Workshop on Tackling Climate Change with Machine Learning .', text='Luccioni, S.; Baylor, E.; and Duchene, N. 2020. Analyzing Sustainability Reports Using Natural Language Processing. In NeurIPS 2020 Workshop on Tackling Climate Change with Machine Learning .', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 41 ===
텍스트: Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/70', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=734.523, r=558.005, b=660.218, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 342))], orig='Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.', text='Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 42 ===
텍스트: Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. TableFormer: Table Structure Understanding with Transformers. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 4604-4613. Los Alamitos, CA, USA: IEEE Computer Society.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/71', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=655.32, r=558.005, b=602.933, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 257))], orig='Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. TableFormer: Table Structure Understanding with Transformers. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 4604-4613. Los Alamitos, CA, USA: IEEE Computer Society.', text='Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. TableFormer: Table Structure Understanding with Transformers. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 4604-4613. Los Alamitos, CA, USA: IEEE Computer Society.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 43 ===
텍스트: Pfitzmann, B.; et al. 2022. DocLayNet: A Large HumanAnnotated Dataset for Document-Layout Segmentation.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/72', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=598.035, r=558.005, b=578.524, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 103))], orig='Pfitzmann, B.; et al. 2022. DocLayNet: A Large HumanAnnotated Dataset for Document-Layout Segmentation.', text='Pfitzmann, B.; et al. 2022. DocLayNet: A Large HumanAnnotated Dataset for Document-Layout Segmentation.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 44 ===
텍스트: Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou, Y.; Li, W.; and Liu, P. J. 2020. Exploring the Limits of Transfer Learning with a Unified Text-toText Transformer. Journal of Machine Learning Research , 21(140): 1-67.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/73', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=573.627, r=558.005, b=521.239, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 245))], orig='Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou, Y.; Li, W.; and Liu, P. J. 2020. Exploring the Limits of Transfer Learning with a Unified Text-toText Transformer. Journal of Machine Learning Research , 21(140): 1-67.', text='Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.; Matena, M.; Zhou, Y.; Li, W.; and Liu, P. J. 2020. Exploring the Limits of Transfer Learning with a Unified Text-toText Transformer. Journal of Machine Learning Research , 21(140): 1-67.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 45 ===
텍스트: Reimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Inui, K.; Jiang, J.; Ng, V.; and Wan, X., eds., Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , 3982-3992. Hong Kong, China: Association for Computational Linguistics.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/74', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=516.342, r=558.005, b=431.077, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 400))], orig='Reimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Inui, K.; Jiang, J.; Ng, V.; and Wan, X., eds., Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , 3982-3992. Hong Kong, China: Association for Computational Linguistics.', text='Reimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Inui, K.; Jiang, J.; Ng, V.; and Wan, X., eds., Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , 3982-3992. Hong Kong, China: Association for Computational Linguistics.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 46 ===
텍스트: Staar, P. W. J.; et al. 2018. Corpus Conversion Service. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/75', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=426.18, r=558.005, b=395.71, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 163))], orig='Staar, P. W. J.; et al. 2018. Corpus Conversion Service. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM.', text='Staar, P. W. J.; et al. 2018. Corpus Conversion Service. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining . ACM.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 47 ===
텍스트: Tay, Y.; Dehghani, M.; Tran, V. Q.; Garcia, X.; Wei, J.; Wang, X.; Chung, H. W.; Bahri, D.; Schuster, T.; Zheng, S.; Zhou, D.; Houlsby, N.; and Metzler, D. 2023. UL2: Unifying Language Learning Paradigms. In The Eleventh International Conference on Learning Representations .
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/76', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=390.812, r=558.005, b=338.425, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 275))], orig='Tay, Y.; Dehghani, M.; Tran, V. Q.; Garcia, X.; Wei, J.; Wang, X.; Chung, H. W.; Bahri, D.; Schuster, T.; Zheng, S.; Zhou, D.; Houlsby, N.; and Metzler, D. 2023. UL2: Unifying Language Learning Paradigms. In The Eleventh International Conference on Learning Representations .', text='Tay, Y.; Dehghani, M.; Tran, V. Q.; Garcia, X.; Wei, J.; Wang, X.; Chung, H. W.; Bahri, D.; Schuster, T.; Zheng, S.; Zhou, D.; Houlsby, N.; and Metzler, D. 2023. UL2: Unifying Language Learning Paradigms. In The Eleventh International Conference on Learning Representations .', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 48 ===
텍스트: Touvron, H.; et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/77', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=333.527, r=558.005, b=314.016, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 96))], orig='Touvron, H.; et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.', text='Touvron, H.; et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 49 ===
텍스트: Webersinke, N.; Kraus, M.; Bingler, J.; and Leippold, M. 2022. ClimateBERT: A Pretrained Language Model for Climate-Related Text. In Proceedings of AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges .
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/78', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=309.119, r=558.005, b=256.731, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 226))], orig='Webersinke, N.; Kraus, M.; Bingler, J.; and Leippold, M. 2022. ClimateBERT: A Pretrained Language Model for Climate-Related Text. In Proceedings of AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges .', text='Webersinke, N.; Kraus, M.; Bingler, J.; and Leippold, M. 2022. ClimateBERT: A Pretrained Language Model for Climate-Related Text. In Proceedings of AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges .', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 50 ===
텍스트: Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean, J.; and Fedus, W. 2022. Emergent Abilities of Large Language Models. Transactions on Machine Learning Research . Survey Certification.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/79', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=251.83400000000006, r=558.005, b=188.48699999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 308))], orig='Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean, J.; and Fedus, W. 2022. Emergent Abilities of Large Language Models. Transactions on Machine Learning Research . Survey Certification.', text='Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean, J.; and Fedus, W. 2022. Emergent Abilities of Large Language Models. Transactions on Machine Learning Research . Survey Certification.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 51 ===
텍스트: Zhang, M.; et al. 2023. WeLayout: WeChat Layout Analysis System for the ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. ArXiv , abs/2305.06553.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/80', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=183.59000000000003, r=558.005, b=142.16100000000006, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 172))], orig='Zhang, M.; et al. 2023. WeLayout: WeChat Layout Analysis System for the ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. ArXiv , abs/2305.06553.', text='Zhang, M.; et al. 2023. WeLayout: WeChat Layout Analysis System for the ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents. ArXiv , abs/2305.06553.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

=== 청크 52 ===
텍스트: Zhong, X.; et al. 2019. PubLayNet: Largest Dataset Ever for Document Layout Analysis. In 2019 International Conference on Document Analysis and Recognition (ICDAR) , 1015-1022.
메타데이터: schema_name='docling_core.transforms.chunker.DocMeta' version='1.0.0' doc_items=[TextItem(self_ref='#/texts/81', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=137.26300000000003, r=558.005, b=95.83500000000004, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 176))], orig='Zhong, X.; et al. 2019. PubLayNet: Largest Dataset Ever for Document Layout Analysis. In 2019 International Conference on Document Analysis and Recognition (ICDAR) , 1015-1022.', text='Zhong, X.; et al. 2019. PubLayNet: Largest Dataset Ever for Document Layout Analysis. In 2019 International Conference on Document Analysis and Recognition (ICDAR) , 1015-1022.', formatting=None, hyperlink=None)] headings=['References'] captions=None origin=DocumentOrigin(mimetype='application/pdf', binary_hash=13823681836276983029, filename='2311.18481v1.pdf', uri=None)

==================================================

