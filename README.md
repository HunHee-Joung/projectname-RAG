## ê°œìš” (Overview)

ì´ ë…¸íŠ¸ë¶ì€ **ì§€ëŠ¥í˜• í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(Intelligent Hybrid Search) ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•˜ê³  ì‹¤í–‰í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. PDFì™€ ê°™ì€ ë¬¸ì„œë¥¼ ì…ë ¥ë°›ì•„, ì˜ë¯¸ì (Semantic) ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê¸°ë°˜(Lexical) ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì¸ë±ì‹±í•˜ê³ , ë¬¸ì„œì˜ êµ¬ì¡°ì  íŠ¹ì§•ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì‹œ ë™ì ìœ¼ë¡œ ìµœì ì˜ ì¬ì •ë ¬(Reranking) ì „ëµì„ ì ìš©í•˜ëŠ” **ì ì‘í˜• ê²€ìƒ‰(Adaptive Search) API ì„œë²„**ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì¸ë±ì‹±ëœ ë°ì´í„°ë¥¼ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

-----

## ì‚¬ì „ ì¤€ë¹„ (Prerequisites)

ì´ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í”„ë ˆì„ì›Œí¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

  * **ë°ì´í„° ì²˜ë¦¬ ë° ì„ë² ë”©:**
      * `langchain_docling`, `docling`: ë¬¸ì„œë¥¼ êµ¬ì¡°ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì²­í‚¹(Chunking)í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
      * `FlagEmbedding`: `BAAI/bge-m3` ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œë¶€í„° Dense Vector(ì˜ë¯¸)ì™€ Sparse Vector(í‚¤ì›Œë“œ) ì„ë² ë”©ì„ ë™ì‹œì— ìƒì„±í•©ë‹ˆë‹¤.
      * `numpy`: ìˆ˜ì¹˜ ì—°ì‚° ë° ë²¡í„° ì²˜ë¦¬ë¥¼ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
      * `pandas`: ì¸ë±ì‹±ëœ ë°ì´í„°ë¥¼ í‘œ í˜•íƒœë¡œ í™•ì¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
  * **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤:**
      * `qdrant_client`: ê³ ì„±ëŠ¥ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì¸ Qdrantì™€ í†µì‹ í•˜ê¸° ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤.
  * **API ì„œë²„ ë° ê¸°íƒ€:**
      * `fastmcp`: ê²€ìƒ‰ ê¸°ëŠ¥ì„ APIë¡œ ë…¸ì¶œí•˜ê¸° ìœ„í•œ ê²½ëŸ‰ ë¹„ë™ê¸° ì„œë²„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
      * `sklearn`: ê²€ìƒ‰ ê²°ê³¼ì˜ ì ìˆ˜ë¥¼ ì •ê·œí™”(min-max scaling)í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
      * `logging`, `os`, `time`, `re`: í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë¡œê¹…, í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬, ì‹œê°„ ì¸¡ì •, ì •ê·œ í‘œí˜„ì‹ ë“±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

-----

## ìƒì„¸ ë¶„ì„ ë° ì„¤ëª…

### 1\. Qdrant ì¸ë±ì‹± (`1. Qdrant Indexing (dense, sparse).py`)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì›ë³¸ ë¬¸ì„œë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ê°€ê³µí•˜ì—¬ Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

  * **What (ë¬´ì—‡ì„):**
    `HybridSearchEngine` í´ë˜ìŠ¤ëŠ” ì§€ì •ëœ PDF íŒŒì¼ì„ `DoclingLoader`ë¡œ ë¡œë“œí•˜ì—¬ êµ¬ì¡°ì  ì •ë³´ë¥¼ í¬í•¨í•œ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤. ì´í›„ `BGE-M3` ëª¨ë¸ì„ ì‚¬ìš©í•´ ê° ì²­í¬ì—ì„œ Dense ë²¡í„°ì™€ Sparse ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ê³ , í…ìŠ¤íŠ¸ ë° ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ Qdrantì— ì €ì¥(ì¸ë±ì‹±)í•©ë‹ˆë‹¤.

  * **Why (ì™œ):**
    ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë¶„í• ì„ ë„˜ì–´, `HybridChunker`ë¥¼ í†µí•´ ë¬¸ì„œì˜ ì œëª©, í‘œ, ë¦¬ìŠ¤íŠ¸ ê°™ì€ êµ¬ì¡°ì  ìš”ì†Œë¥¼ ìµœëŒ€í•œ ë³´ì¡´í•˜ë©° ì²­í‚¹í•©ë‹ˆë‹¤. ì´ëŠ” ì´í›„ ê²€ìƒ‰ ë‹¨ê³„ì—ì„œ ë¬¸ë§¥ì„ ë” ì˜ ì´í•´í•˜ëŠ” ê¸°ë°˜ì´ ë©ë‹ˆë‹¤. ë˜í•œ Dense(ì˜ë¯¸)ì™€ Sparse(í‚¤ì›Œë“œ) ë²¡í„°ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ì€ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì—¬ì¤ë‹ˆë‹¤. ê¸°ì¡´ ì»¬ë ‰ì…˜ì„ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•˜ëŠ” ê³¼ì •ì„ í†µí•´ í•­ìƒ ìµœì‹  ìƒíƒœì˜ ê¹¨ë—í•œ ì¸ë±ìŠ¤ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

  * **How (ì–´ë–»ê²Œ):**

    1.  **ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë”©**: Qdrant í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³ , ì„ë² ë”©ì„ ìœ„í•œ `BGE-M3` ëª¨ë¸ì„ í•„ìš” ì‹œì ì— í•œ ë²ˆë§Œ ë¡œë“œ(Lazy Loading)í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    2.  **ì»¬ë ‰ì…˜ ìƒì„±**: `dense`ì™€ `sparse` ë²¡í„°ë¥¼ ëª¨ë‘ ì €ì¥í•  ìˆ˜ ìˆë„ë¡ Qdrant ì»¬ë ‰ì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ HNSW ì„¤ì •ì„ í†µí•´ ë¹ ë¥´ê³  ì •í™•í•œ ë²¡í„° ê²€ìƒ‰ í™˜ê²½ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
    3.  **ê·¸ë£¹ ì²­í¬ ìƒì„± (`_create_group_chunks`)**: ì›ë³¸ ì²­í¬ ì™¸ì—, ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ëœ ì²­í¬ë“¤(ì˜ˆ: í•˜ë‚˜ì˜ ì„¹ì…˜ì— ì†í•œ ì—¬ëŸ¬ ë¬¸ë‹¨)ì„ ìš”ì•½í•˜ëŠ” 'ê·¸ë£¹ ì²­í¬'ë¥¼ ì¶”ê°€ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” íŠ¹ì • ì„¹ì…˜ ì „ì²´ì— ëŒ€í•œ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
    4.  **ì„ë² ë”© ë° ì—…ë¡œë“œ (`_embed_and_upload_chunks`)**: ëª¨ë“  ì²­í¬(ì›ë³¸ + ê·¸ë£¹)ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. `model.encode`ë¥¼ í˜¸ì¶œí•˜ì—¬ Dense/Sparse ë²¡í„°ë¥¼ ì–»ê³ , ì´ë¥¼ `PointStruct` í˜•íƒœë¡œ êµ¬ì„±í•˜ì—¬ Qdrantì— `upsert`í•©ë‹ˆë‹¤.
    5.  **ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° ë¶„ì„ (`_extract_metadata`, `_is_contextualized`)**: ê° ì²­í¬ì˜ í˜ì´ì§€ ë²ˆí˜¸, ìš”ì†Œ íƒ€ì…(í‘œ, ì œëª© ë“±), ë¶€ëª¨-ìì‹ ê´€ê³„ ë“±ì˜ êµ¬ì¡°ì  ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì²­í¬ê°€ ì–¼ë§ˆë‚˜ 'êµ¬ì¡°í™”'ë˜ì—ˆëŠ”ì§€ ì ìˆ˜ë¥¼ ë§¤ê²¨ `is_contextualized` í”Œë˜ê·¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ì´ í”Œë˜ê·¸ëŠ” ê²€ìƒ‰ ì‹œ ì ì‘í˜• ë¡œì§ì„ ì„ íƒí•˜ëŠ” í•µì‹¬ ê¸°ì¤€ì´ ë©ë‹ˆë‹¤.

#### ì½”ë“œ ë¸”ë¡: `store_document` í•µì‹¬ ë¡œì§

```python
# index.py

def store_document(self, file_path: str) -> int:
    """ì§€ì •ëœ íŒŒì¼ì„ ë¡œë“œí•˜ê³  Qdrantì— ì¸ë±ì‹±í•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    logger.info(f"ğŸ“ ë¬¸ì„œ ë¡œë”© ë° ì¸ë±ì‹± ì‹œì‘: {file_path}")
    
    # 1. ë¬¸ì„œ ë¡œë“œ ë° ì²­í‚¹
    loader = DoclingLoader(file_path=file_path, chunker=HybridChunker(tokenizer=MODEL_NAME, merge_peers=True, max_context_length=self.config["max_context_length"], contextualize=True))
    chunks = loader.load()
    
    # 2. ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
    if self.client.collection_exists(collection_name=COLLECTION_NAME):
        self.client.delete_collection(collection_name=COLLECTION_NAME)

    self.client.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config={"dense": VectorParams(size=1024, distance=Distance.COSINE, hnsw_config=HnswConfigDiff(m=16, ef_construct=100))},
        sparse_vectors_config={"sparse": SparseVectorParams()}
    )
    
    # 3. í˜ì´ë¡œë“œ ì¸ë±ìŠ¤ ìƒì„± (ë¹ ë¥¸ í•„í„°ë§ìš©)
    self._create_payload_indexes()
    
    # 4. Group ì²­í¬ ìƒì„± ë° ì „ì²´ ì²­í¬ ë³‘í•©
    group_chunks = self._create_group_chunks(chunks)
    all_chunks = chunks + group_chunks
    
    # 5. ì„ë² ë”© ë° ì—…ë¡œë“œ
    self._embed_and_upload_chunks(all_chunks, file_path)
    
    # 6. ê²°ê³¼ ë¶„ì„ ë° ë³´ê³ 
    stats = self._collect_stats(chunks)
    self._log_results(stats, len(chunks), len(group_chunks))
    
    return len(all_chunks)
```
``` log 
2025-07-05 15:50:31,659 - INFO - HTTP Request: GET http://192.168.0.249:6333 "HTTP/1.1 200 OK"<\n>
2025-07-05 15:50:31,660 - INFO - âœ… ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”: 192.168.0.249:6333<\n>
2025-07-05 15:50:32,407 - INFO - ğŸ“ ë¬¸ì„œ ë¡œë”© ë° ì¸ë±ì‹± ì‹œì‘: data/XXXXXXXXXXXXX.pdf<\n>
2025-07-05 15:50:33,559 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]<\n>
2025-07-05 15:50:33,561 - INFO - Going to convert document batch...<\n>
2025-07-05 15:50:33,561 - INFO - Initializing pipeline for StandardPdfPipeline with options hash d291d1f79894f05d312cc90dd3fdf3d3
2025-07-05 15:50:33,562 - INFO - Accelerator device: 'cuda:0'
2025-07-05 15:50:34,838 - INFO - Accelerator device: 'cuda:0'
2025-07-05 15:50:35,670 - INFO - Accelerator device: 'cuda:0'
2025-07-05 15:50:35,938 - INFO - Processing document XXXXXXXXXXXXX.pdf
2025-07-05 15:50:41,454 - INFO - Finished converting document XXXXXXXXXXXXX.pdf in 7.90 sec.
2025-07-05 15:50:41,460 - INFO - deleted item in tree at stack: (213, 8) => #/texts/372
2025-07-05 15:50:41,466 - INFO - deleted item in tree at stack: (213, 6) => #/texts/370
2025-07-05 15:50:41,472 - INFO - deleted item in tree at stack: (213, 5) => #/texts/369
2025-07-05 15:50:41,478 - INFO - deleted item in tree at stack: (213, 4) => #/texts/368
2025-07-05 15:50:41,485 - INFO - deleted item in tree at stack: (213, 3) => #/texts/367
2025-07-05 15:50:41,491 - INFO - deleted item in tree at stack: (213, 2) => #/texts/366
2025-07-05 15:50:41,497 - INFO - deleted item in tree at stack: (197, 7) => #/texts/346
2025-07-05 15:50:41,503 - INFO - deleted item in tree at stack: (197, 6) => #/texts/345
2025-07-05 15:50:41,509 - INFO - deleted item in tree at stack: (197, 5) => #/texts/344
2025-07-05 15:50:41,514 - INFO - deleted item in tree at stack: (197, 4) => #/texts/343
2025-07-05 15:50:41,521 - INFO - deleted item in tree at stack: (197, 3) => #/texts/342
2025-07-05 15:50:41,768 - INFO - deleted item in tree at stack: (197, 2) => #/texts/341
2025-07-05 15:50:41,774 - INFO - deleted item in tree at stack: (197, 1) => #/texts/340
2025-07-05 15:50:41,780 - INFO - deleted item in tree at stack: (195, 2) => #/texts/338
2025-07-05 15:50:44,657 - INFO -   - ê²€ìƒ‰ ê²½ë¡œ ì¶”ì²œ: âœ… Context-Aware Path
2025-07-05 15:50:44,657 - INFO - =================================================================

2025-07-05 15:50:44,820 - INFO - ğŸ‰ ì¸ë±ì‹± ì‘ì—… ì„±ê³µ. ì´ 46ê°œì˜ í¬ì¸íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
```
-----

### 2\. ì ì‘í˜• ê²€ìƒ‰ ì„œë²„ (`2. MCP Server (dense, sparse, rrf).py`)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë°›ì•„ Qdrantì—ì„œ ìµœì ì˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ì¬ì •ë ¬í•˜ì—¬ ë°˜í™˜í•˜ëŠ” API ì„œë²„ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

  * **What (ë¬´ì—‡ì„):**
    `AdaptiveHybridSearch` í´ë˜ìŠ¤ëŠ” ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©í•œ í›„, Qdrantì—ì„œ Dense/Sparse ë²¡í„° ê²€ìƒ‰ì„ ë™ì‹œì— ì‹¤í–‰í•˜ì—¬ 1ì°¨ í›„ë³´êµ°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ê·¸ í›„, ê²€ìƒ‰ëœ ë¬¸ì„œì˜ íŠ¹ì„±(`is_contextualized`)ì— ë”°ë¼ 'Context-Aware ê²½ë¡œ' ë˜ëŠ” 'Simple ê²½ë¡œ'ë¼ëŠ” ë‘ ê°€ì§€ ë‹¤ë¥¸ ì¬ì •ë ¬ ì „ëµ ì¤‘ í•˜ë‚˜ë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

  * **Why (ì™œ):**
    ëª¨ë“  ë¬¸ì„œë‚˜ ì¿¼ë¦¬ì— ë‹¨ì¼í•œ ê²€ìƒ‰ ë°©ì‹ì„ ì ìš©í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. ì¸ë±ì‹± ë‹¨ê³„ì—ì„œ íŒŒì•…ëœ ë¬¸ì„œì˜ **êµ¬ì¡°í™” ì •ë„**ì— ë”°ë¼ ê²€ìƒ‰ ì „ëµì„ ë‹¬ë¦¬í•˜ëŠ” **ì ì‘í˜• ë°©ì‹**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. êµ¬ì¡°í™”ê°€ ì˜ ëœ ë¬¸ì„œì˜ ê²½ìš°, ë¶€ëª¨-ìì‹ ê´€ê³„ ê°™ì€ í’ë¶€í•œ ë¬¸ë§¥ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”í•˜ê³ , ê·¸ë ‡ì§€ ì•Šì€ ì¼ë°˜ ë¬¸ì„œì˜ ê²½ìš°ì—” ì•ˆì •ì ì¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤. `LRUCache`ë¥¼ ì‚¬ìš©í•´ ë¶€ëª¨ ì²­í¬ ì •ë³´ë¥¼ ìºì‹±í•˜ì—¬ ë°˜ë³µì ì¸ DB ì¡°íšŒë¥¼ í”¼í•´ ì„±ëŠ¥ì„ ë†’ì…ë‹ˆë‹¤.

  * **How (ì–´ë–»ê²Œ):**

    1.  **ì—­í•  ë¶„ë¦¬**: ì½”ë“œë¥¼ `QdrantManager`(DB í†µì‹ ), `Reranker`(ì¬ì •ë ¬ ë¡œì§), `AdaptiveHybridSearch`(ì „ì²´ íë¦„ ì œì–´) í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬í•˜ì—¬ ìœ ì§€ë³´ìˆ˜ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.
    2.  **ì´ˆê¸° ê²€ìƒ‰ (`QdrantManager.search_batch`)**: ì¿¼ë¦¬ë¥¼ Dense/Sparse ë²¡í„°ë¡œ ë³€í™˜ í›„, Qdrantì— `query_batch_points`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ì¢…ë¥˜ì˜ ê²€ìƒ‰ì„ í•œ ë²ˆì˜ ìš”ì²­ìœ¼ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    3.  **ê²½ë¡œ ì„ íƒ (`Reranker.rerank`)**: 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ì˜ ìµœìƒìœ„ ë¬¸ì„œê°€ `is_contextualized` í”Œë˜ê·¸ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ì‹¤í–‰ ê²½ë¡œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    4.  **Context-Aware ê²½ë¡œ (`_context_path`)**:
          * **RRF ìœµí•© (`_rrf_fusion`)**: Denseì™€ Sparse ê²€ìƒ‰ ê²°ê³¼ë¥¼ Reciprocal Rank Fusion(RRF) ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìœµí•©í•©ë‹ˆë‹¤. ì´ëŠ” ë³„ë„ì˜ ê°€ì¤‘ì¹˜ íŠœë‹ ì—†ì´ë„ ì•ˆì •ì ìœ¼ë¡œ ë‘ ê²°ê³¼ë¥¼ í•©ì¹˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.
          * **ë¶€ëª¨ ë¬¸ë§¥ ì¬ì •ë ¬ (`_parent_rerank`)**: ê° ì²­í¬ì˜ **ë¶€ëª¨ ì²­í¬**ë¥¼ DBì—ì„œ ì¡°íšŒ(ìºì‹œ ìš°ì„  í™•ì¸)í•˜ê³ , ë¶€ëª¨ ì²­í¬ì™€ ì¿¼ë¦¬ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ 'ë¶€ëª¨ ë¬¸ë§¥ ì ìˆ˜'ë¥¼ ì›ë˜ ì ìˆ˜ì™€ ê²°í•©í•˜ì—¬, ì¢‹ì€ ë¬¸ë§¥ì— ì†í•œ ì²­í¬ì˜ ìˆœìœ„ë¥¼ ë†’ì—¬ì¤ë‹ˆë‹¤. (ì˜ˆ: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì„¹ì…˜ ì œëª© ì•„ë˜ì— ìˆëŠ” ë¬¸ë‹¨ì— ê°€ì‚°ì  ë¶€ì—¬)
          * **ë‹¤ì–‘ì„± í•„í„°ë§ (`_ensure_diversity`)**: ìµœì¢… ê²°ê³¼ì— ë™ì¼í•œ ë¶€ëª¨ë¥¼ ê°€ì§„ ì²­í¬ê°€ ë„ˆë¬´ ë§ì´ í¬í•¨ë˜ì§€ ì•Šë„ë¡ ì¡°ì ˆí•˜ì—¬, ì‚¬ìš©ìì—ê²Œ ë” ë‹¤ì–‘í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    5.  **Simple ê²½ë¡œ (`_simple_path`)**:
          * Dense ì ìˆ˜ì™€ Sparse ì ìˆ˜ë¥¼ ê°ê° ì •ê·œí™”(0\~1 ìŠ¤ì¼€ì¼)í•œ í›„, ë¯¸ë¦¬ ì •ì˜ëœ ê°€ì¤‘ì¹˜(`dense: 0.6, sparse: 0.4`)ë¡œ í•©ì‚°í•˜ì—¬ ìµœì¢… ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ëŠ” êµ¬ì¡° ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë‚´ëŠ” í‘œì¤€ì ì¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.

#### ì½”ë“œ ë¸”ë¡: `Reranker`ì˜ ì ì‘í˜• ê²½ë¡œ ì„ íƒ ë¡œì§

```python
# retrieve.py

def rerank(self, initial_results: List[List], query_embedding: Dict, top_k: int, timings: Dict) -> List[Dict]:
    # 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ì˜ ì²« ë²ˆì§¸ ì•„ì´í…œì„ í™•ì¸
    first = next((r[0] for r in initial_results if r), None)
    is_contextualized = first and first.payload and first.payload.get("is_contextualized", False)
    
    # is_contextualized ê°’ì— ë”°ë¼ ê²½ë¡œ ë¶„ê¸°
    if is_contextualized:
        logger.info("âš¡ï¸ êµ¬ì¡°í™”ëœ ë¬¸ì„œ ê°ì§€. Context-Aware ê²½ë¡œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        return self._context_path(initial_results, query_embedding, top_k, timings)
    else:
        logger.info("âš¡ï¸ ë¹„êµ¬ì¡°í™” ë¬¸ì„œ ê°ì§€. Simple ê°€ì¤‘í•© ê²½ë¡œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        return self._simple_path(initial_results, top_k)
```

-----

### 3\. ì²­í‚¹ ë¬¸ì„œ ì •ë³´ í™•ì¸ (`3. chunk Check.py` ìŠ¤í¬ë¦½íŠ¸)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì¸ë±ì‹±ì´ ì™„ë£Œëœ í›„, Qdrant ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ì²­í¬ë“¤ì˜ ì •ë³´ë¥¼ ê°œë°œìê°€ ì§ì ‘ ëˆˆìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ìœ í‹¸ë¦¬í‹°ì…ë‹ˆë‹¤.

  * **What (ë¬´ì—‡ì„):**
    `QdrantDataViewer` í´ë˜ìŠ¤ëŠ” `docling_search` ì»¬ë ‰ì…˜ì— ì ‘ì†í•˜ì—¬ ì €ì¥ëœ ëª¨ë“  ë°ì´í„° í¬ì¸íŠ¸(ì²­í¬)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ê° í¬ì¸íŠ¸ì˜ ID, ìš”ì†Œ íƒ€ì…, í˜ì´ì§€ ë²ˆí˜¸, `is_contextualized` ì—¬ë¶€, ë¶€ëª¨/ìì‹ ID, ê·¸ë¦¬ê³  í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° ë“± í•µì‹¬ ì •ë³´ë¥¼ `pandas` DataFrameìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ í„°ë¯¸ë„ì— í‘œ í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

  * **Why (ì™œ):**
    ë³µì¡í•œ ì¸ë±ì‹± ê³¼ì •ì´ ì˜ë„ëŒ€ë¡œ ì˜ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•˜ê¸° ìœ„í•´ í•„ìˆ˜ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `parent_ref`ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€, `element_type`ì´ ì •í™•í•˜ê²Œ ë¶„ë¥˜ë˜ì—ˆëŠ”ì§€, `is_contextualized` í”Œë˜ê·¸ê°€ ì ì ˆíˆ ë¶€ì—¬ë˜ì—ˆëŠ”ì§€ ë“±ì„ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆì–´ ë””ë²„ê¹…ê³¼ ì‹œìŠ¤í…œ íŠœë‹ì— ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.

  * **How (ì–´ë–»ê²Œ):**
    `qdrant_client.scroll` APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìˆœíšŒí•©ë‹ˆë‹¤. ê° í¬ì¸íŠ¸ì˜ `payload`ì—ì„œ í•„ìš”í•œ ì •ë³´ë“¤ì„ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì€ í›„, ì´ë¥¼ `pandas.DataFrame`ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê°€ë…ì„± ë†’ì€ í‘œë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

#### ì½”ë“œ ë¸”ë¡: `display_all_chunks_summary` ë°ì´í„° ìš”ì•½ ë¡œì§

```python
# viewer ìŠ¤í¬ë¦½íŠ¸ (ì¼ë¶€)

def display_all_chunks_summary(self):
    """ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ì²­í¬ì— ëŒ€í•œ ìš”ì•½ ì •ë³´ë¥¼ í‘œë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    # ... (DB ì ‘ì† ë° í¬ì¸íŠ¸ ê°œìˆ˜ í™•ì¸) ...

    # scroll APIë¡œ ëª¨ë“  í¬ì¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
    all_points, _ = self.client.scroll(
        collection_name=COLLECTION_NAME,
        limit=total_points,
        with_payload=True,
        with_vectors=False # ë²¡í„° ë°ì´í„°ëŠ” í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì œì™¸
    )
    
    summary_data = []
    for point in all_points:
        payload = point.payload
        summary_data.append({
            "ID": point.id,
            "Type": payload.get("element_type"),
            "Page": payload.get("page_no"),
            "Is_Ctx": payload.get("is_contextualized"),
            "Parent_ID": payload.get("parent_ref"),
            "Self_ID": payload.get("self_ref"),
            "Text_Preview": (payload.get("text", "")[:70] + "...")
        })
    
    # Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥
    df = pd.DataFrame(summary_data)
    # ... (Pandas ì¶œë ¥ ì˜µì…˜ ì„¤ì •) ...
    print(df)
```

-----

## ê²°ë¡  ë° ìš”ì•½

ì´ ë…¸íŠ¸ë¶ì€ ë¬¸ì„œì˜ êµ¬ì¡°ì  íŠ¹ì§•ì„ ì§€ëŠ¥ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” **ì°¨ì„¸ëŒ€ ì ì‘í˜• í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ**ì˜ ì™„ì „í•œ êµ¬í˜„ì²´ì…ë‹ˆë‹¤.

  * **ì¸ë±ì‹± ë‹¨ê³„**ì—ì„œëŠ” `docling`ê³¼ `BGE-M3` ëª¨ë¸ì„ í†µí•´ ë‹¨ìˆœ í…ìŠ¤íŠ¸ë¥¼ ë„˜ì–´ì„ , ë¬¸ë§¥ ì •ë³´ê°€ í’ë¶€í•œ(context-rich) ë²¡í„° ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
  * **ê²€ìƒ‰ ë‹¨ê³„**ì—ì„œëŠ” ë¬¸ì„œì˜ íŠ¹ì„±ì— ë”°ë¼ RRF, ë¶€ëª¨ ë¬¸ë§¥ ì¬ì •ë ¬, ë‹¤ì–‘ì„± í•„í„°ë§ì„ í¬í•¨í•œ **'Context-Aware' ê³ ê¸‰ ì „ëµ**ê³¼ ì•ˆì •ì ì¸ **'Simple' ê°€ì¤‘í•© ì „ëµ** ì‚¬ì´ë¥¼ ë™ì ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.
  * ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì„ í†µí•´, ì‹œìŠ¤í…œì€ ì–´ë–¤ ì¢…ë¥˜ì˜ ë¬¸ì„œê°€ ì£¼ì–´ì§€ë”ë¼ë„ ê·¸ì— ë§ëŠ” ìµœì ì˜ ê²€ìƒ‰ í’ˆì§ˆì„ ì œê³µí•  ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ í™•ë³´í–ˆìŠµë‹ˆë‹¤.

ê²°ë¡ ì ìœ¼ë¡œ, ì´ ë…¸íŠ¸ë¶ì€ ìµœì‹  ë²¡í„° ê²€ìƒ‰ ê¸°ìˆ ê³¼ ë¬¸ì„œ ì´í•´(Document Understanding) ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬, ì •êµí•˜ê³  íš¨ìœ¨ì ì¸ ì •ë³´ ê²€ìƒ‰ ì†”ë£¨ì…˜ì„ ì–´ë–»ê²Œ ì„¤ê³„í•˜ê³  êµ¬ì¶•í•  ìˆ˜ ìˆëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” í›Œë¥­í•œ ì²­ì‚¬ì§„ì…ë‹ˆë‹¤.
